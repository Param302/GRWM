"""
FastAPI Backend for GRWM - GitHub README Generator
Implements Server-Sent Events (SSE) for real-time streaming
"""
import os
import asyncio
import uuid
import json
from typing import Dict, Optional, AsyncGenerator
from datetime import datetime
from asyncio import Queue

from fastapi import FastAPI, BackgroundTasks
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

from agents import create_detective_graph, create_initial_state

app = FastAPI(title="GRWM API", version="1.0.0")

# CORS Configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",  # Local development
        "https://*.vercel.app",   # Vercel deployments
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# In-memory session storage with event queues (use Redis in production)
active_sessions: Dict[str, Dict] = {}
event_queues: Dict[str, Queue] = {}


class GenerateRequest(BaseModel):
    username: str
    tone: str = "professional"
    style: str = "modern"


@app.get("/")
async def root():
    return {
        "service": "GRWM API",
        "status": "running",
        "version": "1.0.0"
    }


@app.get("/api/health")
async def health_check():
    return {
        "status": "healthy",
        "active_sessions": len(active_sessions),
        "timestamp": datetime.now().isoformat()
    }


@app.post("/api/select-style")
async def select_style(request: dict, background_tasks: BackgroundTasks):
    """
    User selects a README style after CTO analysis
    This triggers the Ghostwriter agent to start
    """
    session_id = request.get("session_id")
    style = request.get("style")

    if not session_id or not style:
        raise HTTPException(
            status_code=400, detail="session_id and style are required")

    if session_id not in active_sessions:
        raise HTTPException(status_code=404, detail="Session not found")

    # Update session with selected style
    active_sessions[session_id]["preferences"]["style"] = style
    active_sessions[session_id]["style_selected"] = True

    print(f"ğŸ¨ Style selected for session {session_id}: {style}")

    # Continue the generation with ghostwriter
    username = active_sessions[session_id]["username"]
    tone = active_sessions[session_id]["preferences"]["tone"]

    background_tasks.add_task(
        continue_with_ghostwriter,
        session_id,
        username,
        tone,
        style
    )

    return {
        "session_id": session_id,
        "style": style,
        "message": "Style selected, continuing generation..."
    }


@app.post("/api/generate")
async def start_generation(request: GenerateRequest, background_tasks: BackgroundTasks):
    """
    Start README generation and return session_id
    Client uses this to connect to SSE endpoint
    """
    session_id = str(uuid.uuid4())
    print(f"\n{'='*60}")
    print(
        f"ğŸš€ NEW REQUEST: Username='{request.username}', Tone='{request.tone}'")
    print(f"ğŸ“‹ Session ID: {session_id}")
    print(f"{'='*60}\n")

    # Initialize session
    active_sessions[session_id] = {
        "status": "starting",
        "username": request.username,
        "events": [],
        "created_at": datetime.now().isoformat(),
        "preferences": {
            "tone": request.tone,
            "style": request.style
        }
    }

    # Create event queue for real-time streaming
    event_queues[session_id] = Queue()

    print(f"âœ… Session initialized: {session_id}")

    # Start agent in background
    print(f"ğŸ”„ Starting background task for agent execution...")
    background_tasks.add_task(
        run_agent,
        session_id,
        request.username,
        request.tone,
        request.style
    )
    print(f"âœ… Background task queued\n")

    return {
        "session_id": session_id,
        "message": "Generation started",
        "stream_url": f"/api/stream/{session_id}"
    }


async def run_agent(session_id: str, username: str, tone: str, style: str):
    """
    Run the LangGraph agent and emit events in real-time
    Uses threading to prevent blocking the async event loop
    """
    import queue as thread_queue
    from threading import Thread

    event_q = event_queues.get(session_id)
    if not event_q:
        print(f"âŒ No queue found for session {session_id}")
        return

    async def emit_event(event_data: Dict):
        """Helper to emit events to both storage and queue"""
        active_sessions[session_id]["events"].append(event_data)
        await event_q.put(event_data)
        print(f"   â””â”€ ğŸ“¤ Event emitted: {event_data.get('type', 'unknown')}")

    try:
        active_sessions[session_id]["status"] = "running"

        # Wait for SSE connection to establish
        print(f"â³ Waiting 0.5 seconds for SSE connection...")
        await asyncio.sleep(0.5)

        # Send initial event with detective stage
        await emit_event({
            "type": "init",
            "stage": "detective",
            "message": f"ğŸš€ Starting investigation for @{username}...",
            "timestamp": datetime.now().isoformat()
        })

        # Create a thread-safe queue for communication between thread and async
        sync_queue = thread_queue.Queue()

        def progress_callback(stage: str, message: str):
            """Callback for agents to emit progress updates"""
            sync_queue.put(('progress', stage, message))

        def run_graph_in_thread():
            """Run LangGraph in a separate thread and push events to queue"""
            try:
                print(f"ğŸ”§ Thread started: Creating LangGraph...")
                app_graph = create_detective_graph(
                    progress_callback=progress_callback)
                initial_state = create_initial_state(
                    username,
                    preferences={"tone": tone, "style": style}
                )

                config = {
                    "configurable": {"thread_id": session_id},
                    "recursion_limit": 15
                }

                print(f"ğŸ”§ Thread: Starting graph stream...")
                for event in app_graph.stream(initial_state, config):
                    event_name = list(event.keys())[0]
                    state = event[event_name]
                    print(f"   â””â”€ ğŸ¯ Thread: Graph event: {event_name}")
                    # Put event in thread-safe queue
                    sync_queue.put(('event', event_name, state))

                # Signal completion
                sync_queue.put(('done', None, None))
                print(f"âœ… Thread: Graph completed")

            except Exception as e:
                print(f"âŒ Thread error: {e}")
                import traceback
                print(f"Thread traceback:\n{traceback.format_exc()}")
                sync_queue.put(('error', str(e), None))

        # Start the graph in a separate thread
        graph_thread = Thread(target=run_graph_in_thread, daemon=True)
        graph_thread.start()
        print(f"ğŸš€ Graph thread started, waiting for events...")

        # Process events as they come from the thread
        while True:
            # Check the thread queue (blocking with timeout)
            try:
                # Use run_in_executor to make queue.get() non-blocking
                loop = asyncio.get_event_loop()
                msg_type, event_name, state = await loop.run_in_executor(
                    None, sync_queue.get, True, 0.01  # block=True, timeout=0.01s
                )

                if msg_type == 'done':
                    print(f"âœ… Received completion signal from graph")
                    break
                elif msg_type == 'error':
                    raise Exception(f"Graph error: {event_name}")
                elif msg_type == 'progress':
                    # Real-time progress from agents
                    stage = event_name  # event_name is stage here
                    message = state  # state is message here
                    print(f"ğŸ“ Progress [{stage}]: {message}")
                    await emit_event({
                        "type": "progress",
                        "stage": stage,
                        "message": message,
                        "timestamp": datetime.now().isoformat()
                    })
                elif msg_type == 'event':
                    print(f"ğŸ“¥ Received event from graph: {event_name}")
                    # Transform and emit immediately
                    event_data = transform_event(event_name, state, username)
                    if event_data:
                        await emit_event(event_data)

                        # CRITICAL: Give frontend time to process this event before next one
                        await asyncio.sleep(0.3)

                        # Emit progress event for next stage when current stage completes
                        if event_data.get('type') == 'detective_complete':
                            print(f"ğŸ¯ Detective done, signaling CTO start...")
                            await emit_event({
                                "type": "cto_progress",
                                "stage": "cto",
                                "message": "ğŸ§  CTO is analyzing your tech stack...",
                                "timestamp": datetime.now().isoformat()
                            })
                            await asyncio.sleep(0.2)
                        elif event_data.get('type') == 'cto_complete':
                            print(f"ğŸ¯ CTO done, waiting for user to select style...")
                            # Store the final state for later use by Ghostwriter
                            active_sessions[session_id]["final_state"] = state
                            await emit_event({
                                "type": "awaiting_style_selection",
                                "stage": "cto",
                                "message": "â¸ï¸ Analysis complete! Choose your README style to continue...",
                                "timestamp": datetime.now().isoformat()
                            })
                            # Stop here - don't continue to Ghostwriter
                            await asyncio.sleep(0.2)

            except thread_queue.Empty:
                # No event yet, continue waiting (very short sleep)
                await asyncio.sleep(0.01)
                continue

        # Don't send completion event here - graph stops after CTO
        # Completion event will be sent after Ghostwriter finishes
        print(f"ğŸ¯ Analysis phase completed, waiting for style selection\n")

    except Exception as e:
        print(f"\nâŒ ERROR in run_agent: {str(e)}")
        import traceback
        print(f"Traceback:\n{traceback.format_exc()}")

        active_sessions[session_id]["status"] = "error"
        error_event = {
            "type": "error",
            "message": f"Error: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }
        active_sessions[session_id]["events"].append(error_event)
        await event_q.put(error_event)
        print(f"ğŸ’¾ Error event stored in session\n")


async def continue_with_ghostwriter(session_id: str, username: str, tone: str, style: str):
    """
    Run Ghostwriter agent manually (not through graph) after style selection
    Uses the stored state from CTO completion
    """
    import queue as thread_queue
    from threading import Thread

    event_q = event_queues.get(session_id)
    if not event_q:
        print(f"âŒ No queue found for session {session_id}")
        return

    async def emit_event(event_data: Dict):
        """Helper to emit events to both storage and queue"""
        active_sessions[session_id]["events"].append(event_data)
        await event_q.put(event_data)
        print(f"   â””â”€ ğŸ“¤ Event emitted: {event_data.get('type', 'unknown')}")

    try:
        # Emit starting message
        await emit_event({
            "type": "ghostwriter_progress",
            "stage": "ghostwriter",
            "message": f"âœï¸ Ghostwriter is crafting your {style} README...",
            "timestamp": datetime.now().isoformat()
        })

        # Get the stored state from CTO completion
        stored_state = active_sessions[session_id].get("final_state")
        if not stored_state:
            raise Exception("No stored state found - CTO must complete first")

        # Create a thread-safe queue for sync/async communication
        sync_queue = thread_queue.Queue()

        def run_ghostwriter_in_thread():
            """Run ghostwriter in separate thread"""
            try:
                from agents import GhostwriterAgent

                print(f"ğŸ”§ Ghostwriter thread started")

                # Initialize ghostwriter
                ghostwriter = GhostwriterAgent()

                # Update state with selected style
                state_with_style = {
                    **stored_state,
                    "preferences": {"tone": tone, "style": style}
                }

                # Run ghostwriter directly (not through graph)
                result_state = ghostwriter(state_with_style)

                # Put result in queue
                sync_queue.put(('event', 'ghostwriter', result_state))
                sync_queue.put(('done', None, None))
                print(f"âœ… Ghostwriter thread completed")

            except Exception as e:
                print(f"âŒ Ghostwriter thread error: {e}")
                import traceback
                print(f"Thread traceback:\n{traceback.format_exc()}")
                sync_queue.put(('error', str(e), None))

        # Start ghostwriter in separate thread
        ghost_thread = Thread(target=run_ghostwriter_in_thread, daemon=True)
        ghost_thread.start()
        print(f"ğŸš€ Ghostwriter thread started")

        # Process events from thread
        while True:
            try:
                loop = asyncio.get_event_loop()
                msg_type, event_name, state = await loop.run_in_executor(
                    None, sync_queue.get, True, 0.01
                )

                if msg_type == 'done':
                    print(f"âœ… Received completion from ghostwriter")
                    break
                elif msg_type == 'error':
                    raise Exception(f"Ghostwriter error: {event_name}")
                elif msg_type == 'event':
                    print(f"ğŸ“¥ Received event from ghostwriter: {event_name}")
                    event_data = transform_event(event_name, state, username)
                    if event_data:
                        await emit_event(event_data)
                        await asyncio.sleep(0.3)

            except thread_queue.Empty:
                await asyncio.sleep(0.01)
                continue

        # Final completion
        await emit_event({
            "type": "done",
            "message": "README generation complete! ğŸ‰",
            "timestamp": datetime.now().isoformat()
        })
        active_sessions[session_id]["status"] = "completed"
        print(f"ğŸ‰ Ghostwriter completed\n")

    except Exception as e:
        print(f"\nâŒ ERROR in continue_with_ghostwriter: {str(e)}")
        import traceback
        print(f"Traceback:\n{traceback.format_exc()}")

        active_sessions[session_id]["status"] = "error"
        error_event = {
            "type": "error",
            "message": f"Error: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }
        await event_q.put(error_event)


def transform_event(event_name: str, state: Dict, username: str) -> Optional[Dict]:
    """Transform agent state into frontend-friendly event"""
    print(f"\nğŸ”„ transform_event called: {event_name}")

    if event_name == "detective":
        # Check for errors first
        if state.get("error"):
            return {
                "type": "error",
                "stage": "detective",
                "message": state["error"],
                "timestamp": datetime.now().isoformat()
            }

        # Check if data collection is complete
        if state.get("raw_data"):
            raw_data = state["raw_data"]
            profile = raw_data.get("profile", {})
            stats = raw_data.get("stats", {})

            return {
                "type": "detective_complete",
                "stage": "detective",
                "data": {
                    "profile": {
                        "name": profile.get("name", username),
                        "username": profile.get("username", username),
                        "bio": profile.get("bio", ""),
                        "avatar_url": profile.get("avatar_url", ""),
                        "location": profile.get("location", ""),
                        "company": profile.get("company", ""),
                        "email": profile.get("email", ""),
                        "twitter": profile.get("twitter", ""),
                        "website": profile.get("website", ""),
                        "public_repos": stats.get("total_repos", 0),
                        "followers": stats.get("followers", 0),
                        "following": stats.get("following", 0),
                    },
                    "stats": {
                        "repos_count": len(raw_data.get("repositories", [])),
                        "total_stars": raw_data.get("social_proof", {}).get("total_stars", 0),
                        "total_forks": raw_data.get("social_proof", {}).get("total_forks", 0),
                    },
                    # Top 5
                    "repositories": raw_data.get("repositories", [])[:5],
                },
                "message": f"âœ… Profile found! Analyzed {len(raw_data.get('repositories', []))} repositories",
                "timestamp": datetime.now().isoformat()
            }
        else:
            # Still in progress
            return {
                "type": "detective_progress",
                "stage": "detective",
                "message": f"ğŸ” Investigating @{username}'s GitHub profile...",
                "timestamp": datetime.now().isoformat()
            }

    elif event_name == "cto":
        # Check for errors
        if state.get("error"):
            return {
                "type": "error",
                "stage": "cto",
                "message": state["error"],
                "timestamp": datetime.now().isoformat()
            }

        # Check if analysis is complete
        if state.get("analysis"):
            analysis = state["analysis"]

            # Extract tech stack from skill domains
            tech_stack = []
            if analysis.get("skill_domains", {}).get("all_skills"):
                # Top 10
                tech_stack = analysis["skill_domains"]["all_skills"][:10]

            return {
                "type": "cto_complete",
                "stage": "cto",
                "data": {
                    "archetype": analysis.get("developer_archetype", {}).get("full_title", "Unknown"),
                    "profile_headline": analysis.get("profile_headline", ""),
                    "grind_score": analysis.get("grind_score", {}),
                    "primary_language": analysis.get("language_dominance", {}).get("primary_language", {}),
                    "top_languages": analysis.get("language_dominance", {}).get("top_5_languages", []),
                    "tech_stack": tech_stack,
                    "key_projects": analysis.get("key_projects", [])[:3],
                    "impact_metrics": analysis.get("impact_metrics", {}),
                    "tech_diversity": analysis.get("tech_diversity", {}),
                    "primary_domains": analysis.get("skill_domains", {}).get("primary_domains", []),
                },
                "message": f"ğŸ§  Analysis complete: {analysis.get('skill_domains', {}).get('personality_comment', '')}",
                "timestamp": datetime.now().isoformat()
            }
        else:
            # Still analyzing
            return {
                "type": "cto_progress",
                "stage": "cto",
                "message": "ğŸ§  The CTO is analyzing your tech stack and contribution patterns...",
                "timestamp": datetime.now().isoformat()
            }

    elif event_name == "ghostwriter":
        # Check for errors
        if state.get("error"):
            return {
                "type": "error",
                "stage": "ghostwriter",
                "message": state["error"],
                "timestamp": datetime.now().isoformat()
            }

        # Check if README is complete
        if state.get("final_markdown"):
            return {
                "type": "ghostwriter_complete",
                "stage": "ghostwriter",
                "data": {
                    "markdown": state["final_markdown"],
                    "length": len(state["final_markdown"]),
                    "word_count": len(state["final_markdown"].split()),
                },
                "message": "âœï¸ README crafted with love and sarcasm!",
                "timestamp": datetime.now().isoformat()
            }
        else:
            # Still writing
            return {
                "type": "ghostwriter_progress",
                "stage": "ghostwriter",
                "message": "âœï¸ The Ghostwriter is crafting your README...",
                "timestamp": datetime.now().isoformat()
            }

    return None


@app.get("/api/stream/{session_id}")
async def stream_events(session_id: str):
    """
    Server-Sent Events (SSE) endpoint
    Streams agent events to frontend in real-time
    """
    print(f"\n{'='*60}")
    print(f"ğŸŒŠ SSE STREAM REQUESTED")
    print(f"Session ID: {session_id}")

    # Check how long since session was created
    if session_id in active_sessions:
        created_at = datetime.fromisoformat(
            active_sessions[session_id]["created_at"])
        elapsed = (datetime.now() - created_at).total_seconds()
        print(f"â±ï¸  Time since session created: {elapsed:.2f}s")
        print(
            f"ğŸ“Š Events in queue: {event_queues[session_id].qsize() if session_id in event_queues else 0}")
    print(f"{'='*60}\n")

    async def event_generator() -> AsyncGenerator[str, None]:
        """Generate SSE events from queue in real-time"""

        if session_id not in active_sessions:
            print(f"âŒ Session not found: {session_id}")
            yield f"data: {json.dumps({'type': 'error', 'message': 'Session not found'})}\n\n"
            return

        queue = event_queues.get(session_id)
        if not queue:
            print(f"âŒ No queue found for session: {session_id}")
            yield f"data: {json.dumps({'type': 'error', 'message': 'No event queue found'})}\n\n"
            return

        print(f"âœ… Session and queue found, starting real-time event streaming...")

        # Send a keepalive comment to establish connection
        yield ": connected\n\n"

        # Stream events from queue in real-time
        try:
            while True:
                # Wait for next event from queue with timeout
                try:
                    event = await asyncio.wait_for(queue.get(), timeout=60.0)
                    print(
                        f"ğŸ“¤ Sending event to client: {event.get('type', 'unknown')}")
                    yield f"data: {json.dumps(event)}\n\n"

                    # Check if this is a completion event
                    if event.get("type") == "complete" or event.get("type") == "error":
                        print(
                            f"ğŸ Stream ending due to {event.get('type')} event")
                        yield f"data: {json.dumps({'type': 'done', 'status': event.get('type')})}\n\n"

                        # Cleanup session after 5 minutes
                        asyncio.create_task(
                            cleanup_session(session_id, delay=300))
                        break

                except asyncio.TimeoutError:
                    # Send keepalive if no events for 60s
                    yield ": keepalive\n\n"
                    print("ğŸ’“ Sent keepalive")

        except Exception as e:
            print(f"âŒ Error in event generator: {str(e)}")
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # Disable nginx buffering
        }
    )


async def cleanup_session(session_id: str, delay: int = 300):
    """Cleanup session and queue after delay"""
    await asyncio.sleep(delay)
    if session_id in active_sessions:
        del active_sessions[session_id]
        print(f"ğŸ§¹ Cleaned up session: {session_id}")
    if session_id in event_queues:
        del event_queues[session_id]
        print(f"ğŸ§¹ Cleaned up queue: {session_id}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "api:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
